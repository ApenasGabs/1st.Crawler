# ğŸ•·ï¸ SimpleCrawl

CLI interativo para criar projetos de web scraping do zero â€” estilo `create-vite`.  
Ideal para quem estÃ¡ comeÃ§ando com scraping e quer uma base sÃ³lida.

## Uso

```bash
# npm
npm create simplecrawl

# yarn
yarn create simplecrawl

# pnpm
pnpm create simplecrawl

# com nome do projeto direto
npm create simplecrawl my-scraper

# flags diretas (pula menus)
npm create simplecrawl -- --engine hybrid --arch 1-modular --dest my-scraper
```

## Fluxo interativo

```
1/3 â€” Engine de extraÃ§Ã£o (tipo de site):
  â¯ ssr      â€” HTTP + Cheerio     (sites server-side rendered)
    csr      â€” Playwright         (sites client-side / SPA)
    hybrid   â€” Cheerio + Playwright fallback (melhor dos dois)

2/3 â€” Arquitetura do projeto:
  â¯ 1-modular        â€” Simples, 1-3 scrapers, fÃ¡cil de comeÃ§ar
    2-ddd-lite       â€” DDD leve, domÃ­nios separados, escalÃ¡vel
    3-plugin-based   â€” Plugins dinÃ¢micos, 6+ scrapers
    4-queue-based    â€” Filas (Redis/Bull), produÃ§Ã£o larga escala

3/3 â€” Nome do projeto (padrÃ£o: my-scraper):
```

## O que Ã© gerado

```
my-scraper/
â”œâ”€â”€ package.json          # DependÃªncias ajustadas Ã  engine escolhida
â”œâ”€â”€ tsconfig.json
â”œâ”€â”€ README.md             # Customizado com engine + arch
â”œâ”€â”€ docs/
â”œâ”€â”€ examples/
â””â”€â”€ src/
    â”œâ”€â”€ domain/types.ts   # ScrapedRecord + RawData (genÃ©rico)
    â”œâ”€â”€ scrapers/
    â”‚   â””â”€â”€ base/         # BaseScraper e/ou BaseHttpScraper
    â”œâ”€â”€ pipeline/         # BrowserPool, ParallelExecutor, merge
    â””â”€â”€ utils/logger.ts
```

## Flags

| Flag | Atalho | DescriÃ§Ã£o |
|---|---|---|
| `--engine` | `-e` | `ssr`, `csr` ou `hybrid` |
| `--arch` | `-a` | `1-modular`, `2-ddd-lite`, `3-plugin-based`, `4-queue-based` |
| `--dest` | `-d` | Nome da pasta destino |

## PublicaÃ§Ã£o no npm

```bash
cd create-simplecrawl
npm login
npm publish
```

ApÃ³s publicado, qualquer pessoa pode rodar `npm create simplecrawl`.
